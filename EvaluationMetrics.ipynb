{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e2121f04f9fc91",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0c/kb824dp55mv5r_ksvh54vyqr0000gn/T/ipykernel_16827/2048336058.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  .apply(lambda x: pd.DataFrame(combinations(x, 2), columns=['artist_a', 'artist_b'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from numpy import exp\n",
    "import networkx as nx\n",
    "import pydot\n",
    "from cdlib import evaluation, NodeClustering\n",
    "\n",
    "\n",
    "#load the excel file\n",
    "path = 'final_dataset.xlsx'\n",
    "dataset = pd.read_excel(path)\n",
    "\n",
    "#select required columns\n",
    "data = dataset[['ExhibitionID', 'ConstituentID']]\n",
    "\n",
    "#find pairs of artists exhibited in the same exhibition\n",
    "pairs = (\n",
    "    data.groupby('ExhibitionID')['ConstituentID']\n",
    "    .apply(lambda x: pd.DataFrame(combinations(x, 2), columns=['artist_a', 'artist_b'])\n",
    "           .assign(weight=1)\n",
    "           ))\n",
    "\n",
    "#find the weights associated with each pair\n",
    "pairs_summed = pairs.groupby(['artist_a', 'artist_b']).agg(['sum', 'count']).reset_index()\n",
    "pairs_summed = pairs_summed[pairs_summed.weight['count'] > 0]\n",
    "\n",
    "#save the result in the form of a dot file\n",
    "output_dot_file = 'input_graph_file.dot'\n",
    "\n",
    "\n",
    "with open(output_dot_file, 'w') as f:\n",
    "    for _, row in pairs_summed.iterrows():\n",
    "       f.write(f'{row[\"artist_a\"].values[0]} {row[\"artist_b\"].values[0]} {row[\"weight\"][\"sum\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab70956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#find ground truth communities\n",
    "def table_to_communities_txt(df, output_file):\n",
    "    grouped = df.groupby('movement')['ConstituentID'].apply(lambda x: ' '.join(x.astype(str).unique()))\n",
    "\n",
    "    #remove duplicates\n",
    "    unique_communities = grouped.drop_duplicates()\n",
    "\n",
    "    # Write the unique communities to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        for community in unique_communities:\n",
    "            file.write(community + '\\n')\n",
    "\n",
    "#dataset\n",
    "excel_file = './final_dataset.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "#output file\n",
    "output_file = 'final_ground_truth.txt'\n",
    "table_to_communities_txt(df, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e41a50839b0983",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091\n",
      "1091\n"
     ]
    }
   ],
   "source": [
    "#use a dot file to create a networkX graph object\n",
    "def create_graph(dot_file_path, weighted=True):\n",
    "    df = pd.read_csv(dot_file_path, delimiter=' ')\n",
    "    df.columns = ['a', 'b', 'weight']\n",
    "    unique_artists = pd.concat([df.a, df.b], ignore_index=True).astype(str).unique()\n",
    "    if weighted:\n",
    "        connections = [(str(r[1].a), str(r[1].b), {'weight': r[1].weight}) for r in df.iterrows()]\n",
    "    else:\n",
    "        connections = [(str(r[1].a), str(r[1].b)) for r in df.iterrows()]\n",
    "    print(len(unique_artists))\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    G.add_nodes_from(unique_artists)\n",
    "    G.add_edges_from(connections)\n",
    "\n",
    "    return G\n",
    "\n",
    "#use the (output) text file to create communities\n",
    "def create_communities(file_path):\n",
    "    communities = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            nodes = [str(node) for node in line.strip().split()]\n",
    "            communities.append(nodes)\n",
    "    return communities\n",
    "\n",
    "#select the dot file used to create the graph\n",
    "G = create_graph('./input_graph_file.dot')\n",
    "G_unweighted = create_graph('./input_graph_file.dot', False)\n",
    "#create communities using the ground truth file and the output file from the algorithm\n",
    "communitiesOUT = create_communities('./test_dpclus.txt')\n",
    "communitiesGT = create_communities('final_ground_truth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth\n",
      "dpclus_weighed.txt\n",
      "-0.21985962409649065\n",
      "Overall F-score: 0.27319696388035425\n"
     ]
    }
   ],
   "source": [
    "#calculate modularity\n",
    "modularityOUT = evaluation.modularity_overlap(G, NodeClustering(communitiesOUT, G, overlap=True)).score\n",
    "modularityGT = evaluation.modularity_overlap(G, NodeClustering(communitiesGT, G, overlap=True)).score\n",
    "\n",
    "#calculate the f score\n",
    "def f_score(predicted, ground_truth):\n",
    "    intersection = len(set(predicted) & set(ground_truth))\n",
    "    if intersection == 0:\n",
    "        return 0\n",
    "    precision = intersection / len(predicted)\n",
    "    recall = intersection / len(ground_truth)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#find the best match in the ground truth \n",
    "best_matches = {}\n",
    "for predicted_community in communitiesOUT:\n",
    "    max_f1 = -1\n",
    "    best_match = None\n",
    "    for gt_community in communitiesGT:\n",
    "        score = f_score(predicted_community, gt_community)\n",
    "        if score > max_f1:\n",
    "            max_f1 = score\n",
    "            best_match = gt_community\n",
    "#    best_matches[tuple(predicted_community)] = tuple(best_match)\n",
    "    best_matches[tuple(predicted_community)] = max_f1\n",
    "\n",
    "#overall f score of the output\n",
    "fscoreOUT = sum(max_f for max_f in best_matches.values()) / len(best_matches)\n",
    "\n",
    "#print results\n",
    "print(\"Ground Truth\")\n",
    "#print(modularityGT)\n",
    "print('dpclus_weighed.txt')\n",
    "print(modularityOUT)\n",
    "print(\"Overall F-score:\", fscoreOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad860e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighed_density(G):\n",
    "    n = nx.number_of_nodes(G)\n",
    "    m = nx.number_of_edges(G)\n",
    "    if m == 0 or n <= 1:\n",
    "        return 0\n",
    "    weighed_m = sum([w['weight'] for _, __, w in G.edges(data=True)])\n",
    "    d = 2 * weighed_m / (n * (n - 1))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44cc14d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1208368721566782"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighed_density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a646c90ed947d11",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m predicted_num_communities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(communitiesOUT)\n\u001b[1;32m     16\u001b[0m predicted_avg_unweighted_density \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mmean(predicted_densities)\n\u001b[0;32m---> 17\u001b[0m predicted_avg_weighted_density \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mmean([weighed_density(G\u001b[38;5;241m.\u001b[39msubgraph(community)) \u001b[38;5;28;01mfor\u001b[39;00m community \u001b[38;5;129;01min\u001b[39;00m communitiesOUT])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     20\u001b[0m predicted_avg_size \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mlen\u001b[39m(community) \u001b[38;5;28;01mfor\u001b[39;00m community \u001b[38;5;129;01min\u001b[39;00m communitiesOUT)\n",
      "Cell \u001b[0;32mIn[39], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m predicted_num_communities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(communitiesOUT)\n\u001b[1;32m     16\u001b[0m predicted_avg_unweighted_density \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mmean(predicted_densities)\n\u001b[0;32m---> 17\u001b[0m predicted_avg_weighted_density \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mmean([\u001b[43mweighed_density\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommunity\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m community \u001b[38;5;129;01min\u001b[39;00m communitiesOUT])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     20\u001b[0m predicted_avg_size \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mlen\u001b[39m(community) \u001b[38;5;28;01mfor\u001b[39;00m community \u001b[38;5;129;01min\u001b[39;00m communitiesOUT)\n",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m, in \u001b[0;36mweighed_density\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m      6\u001b[0m weighed_m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([w[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _, __, w \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39medges(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m      7\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m weighed_m \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m*\u001b[39m (n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43md\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m, in \u001b[0;36mweighed_density\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m      6\u001b[0m weighed_m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([w[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _, __, w \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39medges(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m      7\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m weighed_m \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m*\u001b[39m (n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43md\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "#ground truth stats\n",
    "ground_truth_num_communities = len(communitiesGT)\n",
    "ground_truth_avg_size = statistics.mean(len(community) for community in communitiesGT)\n",
    "ground_truth_std_dev_size = statistics.stdev(len(community) for community in communitiesGT)\n",
    "ground_truth_max_size = max(len(community) for community in communitiesGT)\n",
    "\n",
    "ground_truth_avg_weighted_density = statistics.mean(evaluation.internal_edge_density(G, NodeClustering(communitiesGT, G, overlap=True), summary=False))\n",
    "ground_truth_avg_unweighted_density = statistics.mean(evaluation.internal_edge_density(G, NodeClustering(communitiesGT, G_unweighted, overlap=True), summary=False))\n",
    "ground_truth_proteins_covered = len(set.union(*(set(community) for community in communitiesGT)))\n",
    "\n",
    "predicted_densities = [nx.density(G.subgraph(community)) for community in communitiesOUT]\n",
    "#algorithm output stats\n",
    "predicted_num_communities = len(communitiesOUT)\n",
    "predicted_avg_unweighted_density = statistics.mean(predicted_densities)\n",
    "predicted_avg_weighted_density = statistics.mean([weighed_density(G.subgraph(community)) for community in communitiesOUT])\n",
    "#\n",
    "\n",
    "predicted_avg_size = statistics.mean(len(community) for community in communitiesOUT)\n",
    "predicted_std_dev_size = statistics.stdev(len(community) for community in communitiesOUT)\n",
    "predicted_max_size = max(len(community) for community in communitiesOUT)\n",
    "\n",
    "predicted_avg_unweighted_density = statistics.mean(evaluation.internal_edge_density(G, NodeClustering(communitiesOUT, G_unweighted, overlap=True), summary=False))\n",
    "predicted_avg_weighted_density= statistics.mean(evaluation.internal_edge_density(G, NodeClustering(communitiesOUT, G, overlap=True), summary=False))\n",
    "\n",
    "predicted_proteins_covered = len(set.union(*(set(community) for community in communitiesOUT)))\n",
    "\n",
    "#make a table out of it\n",
    "data = {\n",
    "    \"\": [\"Predicted Communities\", \"Ground-Truth Communities\"],\n",
    "    \"Number of Communities\": [predicted_num_communities, ground_truth_num_communities],\n",
    "    \"Avg. Size (St. Dev.)\": [(predicted_avg_size, predicted_std_dev_size), (ground_truth_avg_size, ground_truth_std_dev_size)],\n",
    "    \"Max Size\": [predicted_max_size, ground_truth_max_size],\n",
    "    \"Avg. Unweighted Density\": [predicted_avg_unweighted_density, ground_truth_avg_unweighted_density],\n",
    "    \"Avg. Weighted Density\": [predicted_avg_weighted_density, ground_truth_avg_weighted_density],\n",
    "    \"Communities Covered\": [predicted_proteins_covered, ground_truth_proteins_covered]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8800c3cd3b546034",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Number of Communities</th>\n",
       "      <th>Avg. Size (St. Dev.)</th>\n",
       "      <th>Max Size</th>\n",
       "      <th>Avg. Unweighted Density</th>\n",
       "      <th>Avg. Weighted Density</th>\n",
       "      <th>Communities Covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Predicted Communities</td>\n",
       "      <td>107</td>\n",
       "      <td>(17.990654205607477, 26.58255042887771)</td>\n",
       "      <td>199</td>\n",
       "      <td>0.876549</td>\n",
       "      <td>0.876549</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ground-Truth Communities</td>\n",
       "      <td>167</td>\n",
       "      <td>(8.706586826347305, 16.352042493271387)</td>\n",
       "      <td>117</td>\n",
       "      <td>1.033245</td>\n",
       "      <td>1.033245</td>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Number of Communities  \\\n",
       "0     Predicted Communities                    107   \n",
       "1  Ground-Truth Communities                    167   \n",
       "\n",
       "                      Avg. Size (St. Dev.)  Max Size  Avg. Unweighted Density  \\\n",
       "0  (17.990654205607477, 26.58255042887771)       199                 0.876549   \n",
       "1  (8.706586826347305, 16.352042493271387)       117                 1.033245   \n",
       "\n",
       "   Avg. Weighted Density  Communities Covered  \n",
       "0               0.876549                 1021  \n",
       "1               1.033245                 1109  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
