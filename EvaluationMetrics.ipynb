{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e2121f04f9fc91",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0c/kb824dp55mv5r_ksvh54vyqr0000gn/T/ipykernel_87742/2744427172.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  .apply(lambda x: pd.DataFrame(combinations(x, 2), columns=['artist_a', 'artist_b'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from numpy import exp\n",
    "import networkx as nx\n",
    "import pydot\n",
    "\n",
    "\n",
    "#load the excel file\n",
    "path = 'final_dataset.xlsx'\n",
    "dataset = pd.read_excel(path)\n",
    "\n",
    "#select required columns\n",
    "data = dataset[['ExhibitionID', 'ConstituentID']]\n",
    "\n",
    "#find pairs of artists exhibited in the same exhibition\n",
    "pairs = (\n",
    "    data.groupby('ExhibitionID')['ConstituentID']\n",
    "    .apply(lambda x: pd.DataFrame(combinations(x, 2), columns=['artist_a', 'artist_b'])\n",
    "           .assign(weight=1)\n",
    "           ))\n",
    "\n",
    "#find the weights associated with each pair\n",
    "pairs_summed = pairs.groupby(['artist_a', 'artist_b']).agg(['sum', 'count']).reset_index()\n",
    "pairs_summed = pairs_summed[pairs_summed.weight['count'] > 0]\n",
    "\n",
    "#save the result in the form of a dot file\n",
    "output_dot_file = 'input_graph_file.dot'\n",
    "\n",
    "#with open(output_dot_file, 'w') as f:\n",
    " #   f.write('graph {\\n')\n",
    "  #  for _, row in pairs_summed.iterrows():\n",
    "   #     # Convert artist IDs and weight to integers\n",
    "    #    artist_a = int(row[\"artist_a\"])\n",
    "     #   artist_b = int(row[\"artist_b\"])\n",
    "      #  weight = int(row[\"weight\"][\"sum\"])\n",
    "       # f.write(f'    {artist_a} -- {artist_b} [weight={weight}];\\n')\n",
    "    #f.write('}\\n')\n",
    "\n",
    "\n",
    "with open(output_dot_file, 'w') as f:\n",
    "    for _, row in pairs_summed.iterrows():\n",
    "       f.write(f'{row[\"artist_a\"].values[0]} {row[\"artist_b\"].values[0]} {row[\"weight\"][\"sum\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab70956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#find ground truth communities\n",
    "def table_to_communities_txt(df, output_file):\n",
    "    grouped = df.groupby('movement')['ConstituentID'].apply(lambda x: ' '.join(x.astype(str).unique()))\n",
    "\n",
    "    #remove duplicates\n",
    "    unique_communities = grouped.drop_duplicates()\n",
    "\n",
    "    # Write the unique communities to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        for community in unique_communities:\n",
    "            file.write(community + '\\n')\n",
    "\n",
    "#dataset\n",
    "excel_file = './final_dataset.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "#output file\n",
    "output_file = 'final_ground_truth.txt'\n",
    "table_to_communities_txt(df, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e41a50839b0983",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091\n"
     ]
    }
   ],
   "source": [
    "#use a dot file to create a networkX graph object\n",
    "def create_graph(dot_file_path):\n",
    "    df = pd.read_csv('./input_graph_file.dot', delimiter=' ')\n",
    "    df.columns = ['a', 'b', 'weight']\n",
    "    unique_artists = pd.concat([df.a, df.b], ignore_index=True).astype(str).unique()\n",
    "    connections = [(str(r[1].a), str(r[1].b), {'weight': r[1].weight}) for r in df.iterrows()]\n",
    "    print(len(unique_artists))\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    G.add_nodes_from(unique_artists)\n",
    "    G.add_edges_from(connections)\n",
    "\n",
    "    return G\n",
    "\n",
    "#use the (output) text file to create communities\n",
    "def create_communities(file_path):\n",
    "    communities = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            nodes = [str(node) for node in line.strip().split()]\n",
    "            communities.append(nodes)\n",
    "    return communities\n",
    "\n",
    "#select the dot file used to create the graph\n",
    "G = create_graph('input_graph_file.dot')\n",
    "\n",
    "#create communities using the ground truth file and the output file from the algorithm\n",
    "communitiesOUT = create_communities('./test_dpclus.txt')\n",
    "communititesGT = create_communities('final_ground_truth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#overall f score of the output\u001b[39;00m\n\u001b[1;32m     31\u001b[0m l \u001b[38;5;241m=\u001b[39m [max_f \u001b[38;5;28;01mfor\u001b[39;00m max_f \u001b[38;5;129;01min\u001b[39;00m best_matches\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m---> 32\u001b[0m fscoreOUT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_f\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_f\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbest_matches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(best_matches)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#print results\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround Truth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "#calculate modularity\n",
    "from cdlib import evaluation, NodeClustering\n",
    "modularityOUT = evaluation.modularity_overlap(G, NodeClustering(communitiesOUT, G, overlap=True)).score\n",
    "modularityGT = evaluation.modularity_overlap(G, NodeClustering(communititesGT, G, overlap=True)).score\n",
    "\n",
    "#modularityOUT = nx.algorithms.community.modularity(G, communitiesOUT)\n",
    "#modularityGT = nx.algorithms.community.modularity(G, communititesGT)\n",
    "\n",
    "#calculate the f score\n",
    "def f_score(predicted, ground_truth):\n",
    "    intersection = len(set(predicted) & set(ground_truth))\n",
    "    if intersection == 0:\n",
    "        return 0\n",
    "    precision = intersection / len(predicted)\n",
    "    recall = intersection / len(ground_truth)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#find the best match in the ground truth \n",
    "best_matches = {}\n",
    "for predicted_community in communitiesOUT:\n",
    "    max_f1 = -1\n",
    "    best_match = None\n",
    "    for gt_community in communititesGT:\n",
    "        score = f_score(predicted_community, gt_community)\n",
    "        if score > max_f1:\n",
    "            max_f1 = score\n",
    "            best_match = gt_community\n",
    "    best_matches[tuple(predicted_community)] = tuple(best_match)\n",
    "\n",
    "#overall f score of the output\n",
    "l = [max_f for max_f in best_matches.values()]\n",
    "fscoreOUT = sum(max_f for max_f in best_matches.values()) / len(best_matches)\n",
    "\n",
    "#print results\n",
    "print(\"Ground Truth\")\n",
    "#print(modularityGT)\n",
    "print('dpclus_weighed.txt')\n",
    "print(modularityOUT)\n",
    "print(\"Overall F-score:\", fscoreOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a646c90ed947d11",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ground truth stats\n",
    "ground_truth_num_communities = len(communitiesGT)\n",
    "ground_truth_avg_size = statistics.mean(len(community) for community in communitiesGT)\n",
    "ground_truth_std_dev_size = statistics.stdev(len(community) for community in communitiesGT)\n",
    "ground_truth_max_size = max(len(community) for community in communitiesGT)\n",
    "ground_truth_densities = [nx.density(G.subgraph(community)) for community in communitiesGT]\n",
    "ground_truth_avg_unweighted_density = statistics.mean(ground_truth_densities)\n",
    "ground_truth_avg_weighted_density = statistics.mean(nx.density(G.subgraph(community), weight='weight') for community in communitiesGT)\n",
    "ground_truth_proteins_covered = len(set.union(*(set(community) for community in communitiesGT)))\n",
    "\n",
    "#algorithm output stats\n",
    "predicted_num_communities = len(communitiesOUT)\n",
    "predicted_avg_size = statistics.mean(len(community) for community in communitiesOUT)\n",
    "predicted_std_dev_size = statistics.stdev(len(community) for community in communitiesOUT)\n",
    "predicted_max_size = max(len(community) for community in communitiesOUT)\n",
    "predicted_densities = [nx.density(G.subgraph(community)) for community in communitiesOUT]\n",
    "predicted_avg_unweighted_density = statistics.mean(predicted_densities)\n",
    "predicted_avg_weighted_density = statistics.mean(nx.density(G.subgraph(community), weight='weight') for community in communitiesOUT)\n",
    "predicted_proteins_covered = len(set.union(*(set(community) for community in communitiesOUT)))\n",
    "\n",
    "#make a table out of it\n",
    "data = {\n",
    "    \"\": [\"Predicted Communities\", \"Ground-Truth Communities\"],\n",
    "    \"Number of Communities\": [predicted_num_communities, ground_truth_num_communities],\n",
    "    \"Avg. Size (St. Dev.)\": [(predicted_avg_size, predicted_std_dev_size), (ground_truth_avg_size, ground_truth_std_dev_size)],\n",
    "    \"Max Size\": [predicted_max_size, ground_truth_max_size],\n",
    "    \"Avg. Unweighted Density\": [predicted_avg_unweighted_density, ground_truth_avg_unweighted_density],\n",
    "    \"Avg. Weighted Density\": [predicted_avg_weighted_density, ground_truth_avg_weighted_density],\n",
    "    \"Communities Covered\": [predicted_proteins_covered, ground_truth_proteins_covered]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800c3cd3b546034",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
